{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61577d9e",
   "metadata": {},
   "source": [
    "# Diabetic Data Cleaning Notebook\n",
    "This notebook performs Phase 1 of the data cleaning process for the diabetic dataset. It loads the raw data, handles missing values, removes expired patients, merges ID descriptions, and validates the final cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f25d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03db2a8",
   "metadata": {},
   "source": [
    "## 1️⃣ Load the raw diabetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab968d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (adjust if needed)\n",
    "RAW_DATA_PATH = '../data/raw/diabetic_data.csv'\n",
    "ID_MAP_PATH = '../data/raw/IDs_mapping.csv'\n",
    "OUTPUT_PATH = '../data/processed/diabetic_data_clean.csv'\n",
    "\n",
    "# Load raw data, converting '?' to NaN\n",
    "df = pd.read_csv(RAW_DATA_PATH, na_values=['?'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6644e",
   "metadata": {},
   "source": [
    "## 2️⃣ Drop `weight` column due to excessive missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132420f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df['weight'].isna().mean() > 0.9:\n",
    "#     df = df.drop(columns=['weight'])\n",
    "#     print('Dropped weight column due to >90% missing values')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from src.data_cleaning import drop_columns_if_missing\n",
    "\n",
    "df = drop_columns_if_missing(df, threshold=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db937191",
   "metadata": {},
   "source": [
    "## 3️⃣ Remove expired patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef54d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "expired_ids = [11,19,20,21]  # Expired discharge_disposition_id\n",
    "df = df[~df['discharge_disposition_id'].isin(expired_ids)]\n",
    "print(f'Remaining rows after removing expired patients: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395a9f8",
   "metadata": {},
   "source": [
    "## 4️⃣ Load and merge ID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda95758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- 4️⃣ Load and merge ID mappings ---------------- #\n",
    "\n",
    "# Function to parse the IDs_mapping.csv into separate DataFrames\n",
    "def load_mapping_sections(mapping_csv_path):\n",
    "    \"\"\"\n",
    "    Parse IDs_mapping.csv which contains multiple mapping tables\n",
    "    separated by header rows and blank lines.\n",
    "    Returns three DataFrames: admission_type, discharge_disposition, admission_source\n",
    "    \"\"\"\n",
    "    sections = {\n",
    "        \"admission_type_id\": [],\n",
    "        \"discharge_disposition_id\": [],\n",
    "        \"admission_source_id\": []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "\n",
    "    with open(mapping_csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Detect section headers\n",
    "            if line.startswith(\"admission_type_id\"):\n",
    "                current_section = \"admission_type_id\"\n",
    "                continue\n",
    "            elif line.startswith(\"discharge_disposition_id\"):\n",
    "                current_section = \"discharge_disposition_id\"\n",
    "                continue\n",
    "            elif line.startswith(\"admission_source_id\"):\n",
    "                current_section = \"admission_source_id\"\n",
    "                continue\n",
    "\n",
    "            # Skip malformed lines\n",
    "            if \",\" not in line or current_section is None:\n",
    "                continue\n",
    "\n",
    "            id_val, desc = line.split(\",\", 1)\n",
    "            if id_val.isdigit():\n",
    "                sections[current_section].append(\n",
    "                    {\"id\": int(id_val), \"description\": desc.strip('\"')}\n",
    "                )\n",
    "\n",
    "    # Convert each section to DataFrame\n",
    "    admission_type_df = pd.DataFrame(sections[\"admission_type_id\"])\n",
    "    discharge_df = pd.DataFrame(sections[\"discharge_disposition_id\"])\n",
    "    admission_source_df = pd.DataFrame(sections[\"admission_source_id\"])\n",
    "\n",
    "    return admission_type_df, discharge_df, admission_source_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mapping CSV\n",
    "admission_type_map, discharge_map, admission_source_map = load_mapping_sections(ID_MAP_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460284dc",
   "metadata": {},
   "source": [
    "### Note: The mapping CSV contains multiple sections. For simplicity, we'll create separate mappings manually based on the earlier CSV content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d18d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map numeric IDs to descriptions\n",
    "def merge_id_descriptions_safe(df, mapping_df, id_col, new_col_name):\n",
    "    \"\"\"\n",
    "    Maps numeric IDs to descriptions safely without creating extra columns.\n",
    "    \"\"\"\n",
    "    mapping_dict = mapping_df.set_index('id')['description'].to_dict()\n",
    "    df[new_col_name] = df[id_col].map(mapping_dict)\n",
    "    print(f\"Mapped '{id_col}' to '{new_col_name}'\")\n",
    "    return df\n",
    "\n",
    "# Merge all three mappings into the main DataFrame\n",
    "df = merge_id_descriptions_safe(df, admission_type_map, 'admission_type_id', 'admission_type_desc')\n",
    "df = merge_id_descriptions_safe(df, discharge_map, 'discharge_disposition_id', 'discharge_desc')\n",
    "df = merge_id_descriptions_safe(df, admission_source_map, 'admission_source_id', 'admission_source_desc')\n",
    "\n",
    "# Check results\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e13b6",
   "metadata": {},
   "source": [
    "## 5️⃣ Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f'Removed {initial_count - len(df)} duplicate rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943af4c",
   "metadata": {},
   "source": [
    "## 6️⃣ Validate cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c98c36",
   "metadata": {},
   "source": [
    "## 7️⃣ Save cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ab22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f'Saved cleaned dataset to {OUTPUT_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b218ca",
   "metadata": {},
   "source": [
    "## Cleaning Decisions Summary:\n",
    "- **Missing values**: Replaced '?' with NaN for proper handling.\n",
    "- **Weight column**: Dropped due to >90% missing values.\n",
    "- **Expired patients**: Removed patients with `discharge_disposition_id` 11.\n",
    "- **ID mappings**: Merged human-readable descriptions for admission type, discharge disposition, and admission source.\n",
    "- **Duplicates**: Removed duplicate rows to ensure clean data.\n",
    "- **Validation**: Dataset info and descriptive stats checked post-cleaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
